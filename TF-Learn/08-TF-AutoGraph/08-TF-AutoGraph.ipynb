{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08-TF-AutoGraph\n",
    "tf.function的一个很酷的新功能是AutoGraph，它允许使用自然的Python语法编写图形代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一 tf.function装饰器\n",
    "当使用tf.function注释函数时，可以像调用任何其他函数一样调用它。 它将被编译成图，这意味着可以获得更快执行，更好地在GPU或TPU上运行或导出到SavedModel。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0.16079356, 0.21452281, 0.20754547],\n",
       "       [0.64166474, 1.0237459 , 1.1091696 ],\n",
       "       [0.60946167, 0.7407483 , 0.91928065]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def simple_nn_layer(x, y):\n",
    "    return tf.nn.relu(tf.matmul(x, y))\n",
    "\n",
    "\n",
    "x = tf.random.uniform((3, 3))\n",
    "y = tf.random.uniform((3, 3))\n",
    "\n",
    "simple_nn_layer(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们检查注释的结果，我们可以看到它是一个特殊的可调用函数，它处理与TensorFlow运行时的所有交互。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x7fccffb4be10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_nn_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果代码使用多个函数，则无需对它们进行全部注释 - 从带注释函数调用的任何函数也将以图形模式运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_layer(x):\n",
    "    return 2 * x + 1\n",
    "\n",
    "@tf.function\n",
    "def deep_net(x):\n",
    "    return tf.nn.relu(linear_layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x7fcd00f68550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.linear_layer(x)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二 使用python控制流程\n",
    "在tf.function中使用依赖于数据的控制流时，可以使用Python控制流语句，AutoGraph会将它们转换为适当的TensorFlow操作。 例如，如果语句依赖于Tensor，则语句将转换为tf.cond（）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def square_if_positive(x):\n",
    "  if x > 0:\n",
    "    x = x * x\n",
    "  else:\n",
    "    x = 0\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square_if_positive(2) = 4\n",
      "square_if_positive(-2) = 0\n"
     ]
    }
   ],
   "source": [
    "# 注意这里输入为 tf.constant\n",
    "print('square_if_positive(2) = {}'.format(square_if_positive(tf.constant(2))))\n",
    "print('square_if_positive(-2) = {}'.format(square_if_positive(tf.constant(-2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoGraph支持常见的Python语句，例如while，if，break，continue和return，支持嵌套。 这意味着可以在while和if语句的条件下使用Tensor表达式，或者在for循环中迭代Tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_even(items):\n",
    "  s = 0\n",
    "  for c in items:\n",
    "    if c % 2 > 0:\n",
    "      continue\n",
    "    s += c\n",
    "  return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_even(tf.constant([10, 12, 15, 20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoGraph还为高级用户提供了低级API。 例如，我们可以使用它来查看生成的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__sum_even(items):\n",
      "    with ag__.FunctionScope('sum_even', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "        s = 0\n",
      "\n",
      "        def get_state_2():\n",
      "            return (s,)\n",
      "\n",
      "        def set_state_2(vars_):\n",
      "            nonlocal s\n",
      "            (s,) = vars_\n",
      "\n",
      "        def loop_body(itr):\n",
      "            nonlocal s\n",
      "            c = itr\n",
      "            continue_ = False\n",
      "\n",
      "            def get_state():\n",
      "                return (continue_,)\n",
      "\n",
      "            def set_state(vars_):\n",
      "                nonlocal continue_\n",
      "                (continue_,) = vars_\n",
      "\n",
      "            def if_body():\n",
      "                nonlocal continue_\n",
      "                continue_ = True\n",
      "\n",
      "            def else_body():\n",
      "                nonlocal continue_\n",
      "                pass\n",
      "            ag__.if_stmt(((ag__.ld(c) % 2) > 0), if_body, else_body, get_state, set_state, ('continue_',), 1)\n",
      "\n",
      "            def get_state_1():\n",
      "                return (s,)\n",
      "\n",
      "            def set_state_1(vars_):\n",
      "                nonlocal s\n",
      "                (s,) = vars_\n",
      "\n",
      "            def if_body_1():\n",
      "                nonlocal s\n",
      "                s = ag__.ld(s)\n",
      "                s += c\n",
      "\n",
      "            def else_body_1():\n",
      "                nonlocal s\n",
      "                pass\n",
      "            ag__.if_stmt(ag__.not_(continue_), if_body_1, else_body_1, get_state_1, set_state_1, ('s',), 1)\n",
      "        c = ag__.Undefined('c')\n",
      "        continue_ = ag__.Undefined('continue_')\n",
      "        ag__.for_stmt(ag__.ld(items), None, loop_body, get_state_2, set_state_2, ('s',), {'iterate_names': 'c'})\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(s)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tf.autograph.to_code(sum_even, experimental_optional_features=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def fizzbuzz(n):\n",
    "    msg = tf.constant('')\n",
    "    for i in tf.range(n):\n",
    "        if tf.equal(i % 3, 0):\n",
    "            msg += 'Fizz'\n",
    "        elif tf.equal(i % 5, 0):\n",
    "            msg += 'Buzz'\n",
    "        else:\n",
    "            msg += tf.as_string(i)\n",
    "        msg += '\\n'\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fizz\n",
      "1\n",
      "2\n",
      "Fizz\n",
      "4\n",
      "Buzz\n",
      "Fizz\n",
      "7\n",
      "8\n",
      "Fizz\n",
      "Buzz\n",
      "11\n",
      "Fizz\n",
      "13\n",
      "14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fizzbuzz(tf.constant(15)).numpy().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三 Keras和AutoGraph\n",
    "也可以将tf.function与对象方法一起使用。 例如，可以通过注释模型的调用函数来装饰自定义Keras模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.models.Model):\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, input_data):\n",
    "        if tf.reduce_mean(input_data) > 0:\n",
    "            return input_data\n",
    "        else:\n",
    "            return input_data // 2\n",
    "\n",
    "\n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([-1, -2], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(tf.constant([-2, -4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就像在eager模式下一样，你可以使用带有副作用的操作，比如通常在tf.function中的tf.assign或tf.print，它会插入必要的控件依赖项以确保它们按顺序执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable(5)\n",
    "\n",
    "@tf.function\n",
    "def find_next_odd():\n",
    "    v.assign(v + 1)\n",
    "    if tf.equal(v % 2, 0):\n",
    "        v.assign(v + 1)\n",
    "\n",
    "find_next_odd()\n",
    "\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四 用AutoGraph训练一个简单模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mnist_features_and_labels(x, y):\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    return x, y\n",
    "\n",
    "def mnist_dataset():\n",
    "    (x, y), _ = tf.keras.datasets.mnist.load_data()\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    ds = ds.map(prepare_mnist_features_and_labels)\n",
    "    ds = ds.take(20000).shuffle(20000).batch(100)\n",
    "    return ds\n",
    "\n",
    "train_dataset = mnist_dataset()\n",
    "model = tf.keras.Sequential((\n",
    "    tf.keras.layers.Reshape(target_shape=(28 * 28,), input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)))\n",
    "model.build()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "compute_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "compute_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10 : loss 1.87191153 ; accuracy 0.291\n",
      "Step 20 : loss 1.12330246 ; accuracy 0.4915\n",
      "Step 30 : loss 0.79729563 ; accuracy 0.586\n",
      "Step 40 : loss 0.664484918 ; accuracy 0.64925\n",
      "Step 50 : loss 0.623919427 ; accuracy 0.6912\n",
      "Step 60 : loss 0.357091486 ; accuracy 0.716166675\n",
      "Step 70 : loss 0.372655898 ; accuracy 0.741\n",
      "Step 80 : loss 0.480072021 ; accuracy 0.7585\n",
      "Step 90 : loss 0.482334226 ; accuracy 0.772666693\n",
      "Step 100 : loss 0.298391968 ; accuracy 0.7852\n",
      "Step 110 : loss 0.251136392 ; accuracy 0.796909094\n",
      "Step 120 : loss 0.220183715 ; accuracy 0.806666672\n",
      "Step 130 : loss 0.267776251 ; accuracy 0.814384639\n",
      "Step 140 : loss 0.242873058 ; accuracy 0.821714282\n",
      "Step 150 : loss 0.304112345 ; accuracy 0.827466667\n",
      "Step 160 : loss 0.317876846 ; accuracy 0.83325\n",
      "Step 170 : loss 0.283043 ; accuracy 0.838117659\n",
      "Step 180 : loss 0.508346081 ; accuracy 0.841666639\n",
      "Step 190 : loss 0.260991722 ; accuracy 0.845947385\n",
      "Step 200 : loss 0.162355036 ; accuracy 0.8507\n",
      "Final step tf.Tensor(200, shape=(), dtype=int32) : loss tf.Tensor(0.16235504, shape=(), dtype=float32) ; accuracy tf.Tensor(0.8507, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def train_one_step(model, optimizer, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x)\n",
    "        loss = compute_loss(y, logits)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    compute_accuracy(y, logits)\n",
    "    return loss\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train(model, optimizer):\n",
    "    train_ds = mnist_dataset()\n",
    "    step = 0\n",
    "    loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    for x, y in train_ds:\n",
    "        step += 1\n",
    "        loss = train_one_step(model, optimizer, x, y)\n",
    "        if tf.equal(step % 10, 0):\n",
    "            tf.print('Step', step, ': loss', loss, '; accuracy', compute_accuracy.result())\n",
    "    return step, loss, accuracy\n",
    "\n",
    "step, loss, accuracy = train(model, optimizer)\n",
    "print('Final step', step, ': loss', loss, '; accuracy', compute_accuracy.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五 关于批处理的说明\n",
    "在实际应用中，批处理对性能至关重要。 转换为AutoGraph的最佳代码是在批处理级别决定控制流的代码。 如果在单个示例级别做出决策，请尝试使用批处理API来维护性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5, -4, -3, -2, -1, 0, 1, 4, 9, 16]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square_if_positive(x):\n",
    "    return [i ** 2 if i > 0 else i for i in x]\n",
    "\n",
    "square_if_positive(range(-5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([-5, -4, -3, -2, -1,  0,  1,  4,  9, 16], dtype=int32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在tensorflow中上面的代码应该改成下面所示\n",
    "@tf.function\n",
    "def square_if_positive_naive(x):\n",
    "    result = tf.TensorArray(tf.int32, size=x.shape[0])\n",
    "    for i in tf.range(x.shape[0]):\n",
    "        if x[i] > 0:\n",
    "            result = result.write(i, x[i] ** 2)\n",
    "        else:\n",
    "            result = result.write(i, x[i])\n",
    "    return result.stack()\n",
    "\n",
    "\n",
    "square_if_positive_naive(tf.range(-5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([-5, -4, -3, -2, -1,  0,  1,  4,  9, 16], dtype=int32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以这么写\n",
    "def square_if_positive_vectorized(x):\n",
    "    return tf.where(x > 0, x ** 2, x)\n",
    "\n",
    "square_if_positive_vectorized(tf.range(-5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
